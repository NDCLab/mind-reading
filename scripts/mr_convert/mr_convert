#!/bin/env python

"""mr_convert

Usage:
    mr_convert <file>...

Output format

c = channels
s = sample
tm = trial segment
0 = time 0 marker

c  |ssssss|sssss|...|
tm |t_____|t____|...|
0  |___m__|_m___|...|
"""

import os
import sys
import re
import glob
import scipy
import numpy as np
from os import path as pt
from docopt import docopt
from scipy import io as sio
from pprint import pprint


def main(args):
    ch_info = {}
    # Iterate over all paths passed into program
    for path in args["<file>"]:
        basename = pt.splitext(pt.basename(path))[0]
        # uses the first to parts of the mat file name,
        # increase slice length to increase matching amount
        common_name = "_".join(basename.split("_")[0:2])
        # load mat file
        mat = sio.loadmat(path)

        # Usesful to know on which file it is one
        print(basename)
        # extract important information
        labels, channels = process_mat_file(mat)
        # CARE: does not check if overwriting files
        output_to_csv(f"output/{basename}.csv", channels, labels)

        # Get common channel info
        if common_name not in ch_info:
            ch_info[common_name] = process_channel_info(mat)

    for cn in ch_info.keys():
        # CARE: does not check if overwriting files
        output_to_csv_ci(f"output/{cn}_chanInfo.csv", ch_info[cn])


# Simple save, no overwrite check
def output_to_csv(path, channels, labels):
    # output sample data to csv
    arr = []
    for label in labels:
        arr.append(channels[label])

    arr = np.array(arr)
    np.savetxt(path, arr, delimiter=",", fmt="%f")


def output_to_csv_ci(path, ch_info):
    # comments removes "#" from header, otherwise #Phi
    # headr is for the first row
    np.savetxt(path, ch_info, header="Phi,Theta,Radius,Name",
               delimiter=",", fmt="%s", comments="")
    # np.savetxt(path, ch_info, delimiter=",", fmt="%s")


# get phi,theta,radius,name
def process_channel_info(mat):
    arr = []
    for e in mat["Channels"][0]:
        temp = []
        for d in e:
            # without this part only string is extracted
            for c in d:
                temp.append(c.flatten()[0])
        arr.append(temp)

    return np.array(arr)


# Uses the mat files we discussed
# It extracts:
#   Channel labels
#   Channel data (mV)
#   stim labels
def process_mat_file(mat):
    segment_count = mat["SegmentCount"][0][0]
    sample_rate = mat["SampleRate"][0][0]

    # get a "nicer" list of the markers
    markers = get_markers(mat["Markers"])
    # get correct marker based on "Time 0" marker, returns [(pos, value),...]
    stim_labels = get_stim_label(markers)
    # generate marker position for csv
    label_row = fill_with_pos(stim_labels, sample_rate, segment_count)

    # Channel Labels "Fp1, ..., etc"
    ch_labels = list(map(lambda e: e[3][0], mat["Channels"][0][..., ]))

    # Channel mV
    channels = {}
    for label in ch_labels:
        channels[label] = mat[label].flatten()

    # Offset using sample_rate (1024)
    # TODO: optimization, iterate over segment count vs samples
    segment_offset = [0]*sample_rate*segment_count
    for i, _e in enumerate(segment_offset):
        if i % sample_rate == 0:
            segment_offset[i] = 1

    # Add segment marker and time 0 marker
    channels["segment_marker"] = np.array(segment_offset, dtype=float)
    channels["stim_label"] = np.array(label_row, dtype=float)

    # Chan Labels
    ch_labels.append("segment_marker")
    ch_labels.append("stim_label")

    return (ch_labels, channels)


# Creates a zeroed array to act as a marker in the csv
# segment = trial from mat file
# sample_rate is the same as the mat file (prob 1024)
# label = (trial, pos in trial, label value)
def fill_with_pos(labels, sample_rate, segment_count):
    # generate marker in data
    row = ["0"]*sample_rate*segment_count
    for label in labels:
        segment = label[0]
        sample_pos = label[1]
        value = label[2]
        index = (segment * sample_rate) + sample_pos - 1
        row[index] = value

    return row


# Get Stimulus label
# Uses regular expression to match against "Stimulus" and "S 11"
#   For the label, it uses groups to extract the numerical value
# Note: a marker element is flattened array of up to 3 cell arrays from matlab
def get_stim_label(markers):
    zero_pos = get_time_zero(markers)
    labels = []

    count = 0
    for i, marker in enumerate(markers):
        pos = zero_pos[i]
        rv_marker = list(reversed(marker))
        markers_at_zero = 0
        for j, e in enumerate(rv_marker):
            if j+1 < len(rv_marker) and re.match(r"Stimulus", str(e)) and rv_marker[j+1] == pos:
                if match := re.match(r"[A-Z]\s+(\d+)", str(rv_marker[j+3])):
                    markers_at_zero += 1
                    st_type = int(match.group(1))
                    labels.append((i, pos, st_type))

        # Uncomment to check if Markers overlap, and grep output for ": [2-9]+"
        # if markers_at_zero > 0:
            # print(f"marker at zero count: {markers_at_zero}")

    return labels


# Not very straight forward due to how mat files are converted to numpy arrays
def get_markers(markers):
    marker_comp = []
    for i, v in enumerate(markers):
        # marker components (up to three parts) flattened into one list
        marker_comp.append([])
        # three comps
        for e1 in v:
            # four values
            for e2 in e1:
                tmp = e2.flatten()
                if (len(tmp) > 0):
                    marker_comp[i].append(tmp[0])
    return marker_comp


# Not used (but left as example for my self)
def get_time_zero(markers):
    # get Time 0 sample frame
    pos = []
    for i in markers:
        if "Time 0" in i:
            pos.append(i[i.index("Time 0") - 1])

    return pos


if __name__ == "__main__":
    args = docopt(__doc__)
    main(args)
